{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOvLnAXmNpOeM5qQRqGBFdt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaXCONlZZr6d","executionInfo":{"status":"ok","timestamp":1728868818033,"user_tz":-330,"elapsed":553,"user":{"displayName":"Saud Mullaji","userId":"18055721788926414856"}},"outputId":"80e9b5d9-9423-4d68-dc39-3e603d0f55a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loss: 0.05866171820583382\n","Loss: 0.0001720084643031533\n","Loss: 0.00017058235758868584\n","Loss: 0.00016933216566801922\n","Loss: 0.00016812057501306276\n","Loss: 0.00016694599373128665\n","Loss: 0.00016580692104430493\n","Loss: 0.0001647019344914858\n","Loss: 0.00016362968496505436\n","Loss: 0.00016258889210689646\n","Input: [[0.66666667 1.        ]\n"," [0.33333333 0.55555556]\n"," [1.         0.66666667]]\n","Actual Output: [[0.92]\n"," [0.86]\n"," [0.89]]\n","Loss: 0.00016157834004070908\n","\n","\n","Predicted Output: [[0.90175578]\n"," [0.86954158]\n"," [0.8978001 ]]\n"]}],"source":["import numpy as np\n","# X = (hours sleeping, hours studying), y = test score of the student\n","X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n","y = np.array(([92], [86], [89]), dtype=float)\n","\n","# scale units\n","X = X/np.amax(X, axis=0) #maximum of X array\n","y = y/100 # maximum test score is 100\n","\n","class NeuralNetwork(object):\n","    def __init__(self):\n","        #parameters\n","        self.inputSize = 2\n","        self.outputSize = 1\n","        self.hiddenSize = 3\n","\n","        #weights\n","        self.W1 = np.random.rand(self.inputSize, self.hiddenSize) # (3x2) weight matrix from input to hidden layer\n","        self.W2 = np.random.rand(self.hiddenSize, self.outputSize) # (3x1) weight matrix from hidden to output layer\n","\n","    def feedForward(self, X):\n","        #forward propogation through the network\n","        self.z = np.dot(X, self.W1) #dot product of X (input) and first set of weights (3x2)\n","        self.z2 = self.sigmoid(self.z) #activation function\n","        self.z3 = np.dot(self.z2, self.W2) #dot product of hidden layer (z2) and second set of weights (3x1)\n","        output = self.sigmoid(self.z3)\n","        return output\n","\n","    def sigmoid(self, s, deriv=False):\n","        if (deriv == True):\n","            return s * (1 - s)\n","        return 1/(1 + np.exp(-s))\n","\n","    def backward(self, X, y, output):\n","        #backward propogate through the network\n","        self.output_error = y - output # error in output\n","        self.output_delta = self.output_error * self.sigmoid(output, deriv=True)\n","\n","        self.z2_error = self.output_delta.dot(self.W2.T) #z2 error: how much our hidden layer weights contribute to output error\n","        self.z2_delta = self.z2_error * self.sigmoid(self.z2, deriv=True) #applying derivative of sigmoid to z2 error\n","\n","        self.W1 += X.T.dot(self.z2_delta) # adjusting first set (input -> hidden) weights\n","        self.W2 += self.z2.T.dot(self.output_delta) # adjusting second set (hidden -> output) weights\n","\n","    def train(self, X, y):\n","        output = self.feedForward(X)\n","        self.backward(X, y, output)\n","\n","NN = NeuralNetwork()\n","\n","for i in range(1000): #trains the NN 1000 times\n","    if (i % 100 == 0):\n","        print(\"Loss: \" + str(np.mean(np.square(y - NN.feedForward(X)))))\n","    NN.train(X, y)\n","\n","print(\"Input: \" + str(X))\n","print(\"Actual Output: \" + str(y))\n","print(\"Loss: \" + str(np.mean(np.square(y - NN.feedForward(X)))))\n","print(\"\\n\")\n","print(\"Predicted Output: \" + str(NN.feedForward(X)))"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"metadata":{"id":"BdcKIOIScDCH","executionInfo":{"status":"ok","timestamp":1728893301316,"user_tz":-330,"elapsed":462,"user":{"displayName":"Saud Mullaji","userId":"18055721788926414856"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#sigmoid function (activation function)\n","def nlinear(x, deriv=False):\n","    if(deriv==True):\n","        return x*(1-x)\n","    return 1/(1+np.exp(-x))"],"metadata":{"id":"xy8OUkLdcKIA","executionInfo":{"status":"ok","timestamp":1728893302752,"user_tz":-330,"elapsed":26,"user":{"displayName":"Saud Mullaji","userId":"18055721788926414856"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#input dataset\n","X = np.array([   [0,0,1],\n","                  [0,1,1],\n","                  [1,0,1],\n","                  [1,1,1]   ])"],"metadata":{"id":"LyFrIj_3cWLm","executionInfo":{"status":"ok","timestamp":1728893305005,"user_tz":-330,"elapsed":14,"user":{"displayName":"Saud Mullaji","userId":"18055721788926414856"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# output dataset\n","y = np.array([[0,0,1,1]]).T\n"],"metadata":{"id":"hvhKbrhmcv8W","executionInfo":{"status":"ok","timestamp":1728893307146,"user_tz":-330,"elapsed":569,"user":{"displayName":"Saud Mullaji","userId":"18055721788926414856"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#send random number for random distribution deterministic\n","np.random.seed(1)"],"metadata":{"id":"aKjysKjwc_E4","executionInfo":{"status":"ok","timestamp":1728893309235,"user_tz":-330,"elapsed":507,"user":{"displayName":"Saud Mullaji","userId":"18055721788926414856"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["synapse0 = 2 * np.random.random((3,1)) - 1"],"metadata":{"id":"jd4R9EW1dL9i","executionInfo":{"status":"ok","timestamp":1728893310990,"user_tz":-330,"elapsed":13,"user":{"displayName":"Saud Mullaji","userId":"18055721788926414856"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["for i in range(1000):\n","  # forward feed\n","  layer0 = X\n","  layer1 = nlinear(np.dot(layer0, synapse0))\n","\n","  #calculate error\n","  layer1_error = y - layer1\n","\n","  #multiply error by input and gradient of sigmoid function\n","  # multipy how much error back propagated\n","  # slope of sigmoid at the values in layer1\n","  layer1_delta = layer1_error * nlinear(layer1, True)\n","\n","#update weights as per the errors back propagates\n","synapse0 += np.dot(layer0.T, layer1_delta)\n","print(\"Output after training\")\n","print(layer1)\n","\n","print(\"Actual Output\")\n","print(y)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"frmENnBzw06O","executionInfo":{"status":"ok","timestamp":1728893854377,"user_tz":-330,"elapsed":464,"user":{"displayName":"Saud Mullaji","userId":"18055721788926414856"}},"outputId":"c1d0358d-dfe6-401f-b72b-c0c282a2eda3"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["Output after training\n","[[0.11916453]\n"," [0.08587064]\n"," [0.93270932]\n"," [0.90587753]]\n","Actual Output\n","[[0]\n"," [0]\n"," [1]\n"," [1]]\n"]}]}]}